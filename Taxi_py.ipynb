{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yann-Xavier/Python/blob/main/Taxi_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importação das bibliotecas necessárias\n",
        "import numpy as np  # Para manipulações de arrays e cálculos matemáticos\n",
        "import gym  # Para carregar o ambiente Taxi-v3\n",
        "import pygame  # Para criar uma visualização interativa\n",
        "import time  # Para controle do intervalo entre frames na visualização\n",
        "\n",
        "# Configuração do ambiente Taxi-v3\n",
        "env = gym.make(\"Taxi-v3\")  # Inicializa o ambiente Taxi-v3 do Gym\n",
        "\n",
        "# Inicializa a tabela Q com zeros\n",
        "# Dimensão: número de estados x número de ações possíveis\n",
        "q_table = np.zeros([env.observation_space.n, env.action_space.n])\n",
        "\n",
        "# Hiperparâmetros para o treinamento\n",
        "alpha = 0.1  # Taxa de aprendizado\n",
        "gamma = 0.6  # Fator de desconto (importância de recompensas futuras)\n",
        "epsilon = 0.1  # Taxa de exploração (probabilidade de ações aleatórias)\n",
        "num_episodes = 1000  # Número total de episódios para treinamento\n",
        "\n",
        "# Configurações do Pygame para visualização\n",
        "pygame.init()  # Inicializa o Pygame\n",
        "screen_size = 500  # Dimensão da janela (500x500 pixels)\n",
        "cell_size = screen_size // 5  # Cada célula na grade tem 100x100 pixels\n",
        "screen = pygame.display.set_mode((screen_size, screen_size))  # Cria a janela do Pygame\n",
        "pygame.display.set_caption(\"Taxi-v3 Visualization\")  # Título da janela do Pygame\n",
        "\n",
        "# Define as cores para os elementos visuais\n",
        "colors = {\n",
        "    \"taxi\": (255, 255, 0),  # Táxi: amarelo\n",
        "    \"passenger\": (0, 255, 0),  # Passageiro: verde\n",
        "    \"destination\": (255, 0, 0),  # Destino: vermelho\n",
        "    \"road\": (200, 200, 200),  # Estrada: cinza\n",
        "}\n",
        "\n",
        "# Função para renderizar o ambiente no Pygame\n",
        "def render_env(state):\n",
        "    \"\"\"\n",
        "    Renderiza o estado atual do ambiente Taxi-v3 na janela do Pygame.\n",
        "    :param state: Estado atual do ambiente (inteiro).\n",
        "    \"\"\"\n",
        "    screen.fill(colors[\"road\"])  # Preenche o fundo com a cor da estrada\n",
        "\n",
        "    # Decodifica o estado para obter posições do táxi, passageiro e destino\n",
        "    taxi_row, taxi_col, passenger, destination = env.unwrapped.decode(state)\n",
        "\n",
        "    # Desenha a grade 5x5\n",
        "    for i in range(5):\n",
        "        for j in range(5):\n",
        "            pygame.draw.rect(screen, (0, 0, 0), (j * cell_size, i * cell_size, cell_size, cell_size), 1)\n",
        "\n",
        "    # Desenha o táxi na posição atual\n",
        "    pygame.draw.rect(screen, colors[\"taxi\"],\n",
        "                     (taxi_col * cell_size + 10, taxi_row * cell_size + 10, cell_size - 20, cell_size - 20))\n",
        "\n",
        "    # Desenha o passageiro (se ainda não foi pego)\n",
        "    if passenger < 4:  # Passageiro está em uma das localizações fixas\n",
        "        passenger_coords = [(0, 0), (0, 4), (4, 0), (4, 3)]  # Locais fixos no ambiente\n",
        "        passenger_row, passenger_col = passenger_coords[passenger]\n",
        "        pygame.draw.circle(screen, colors[\"passenger\"],\n",
        "                           (passenger_col * cell_size + cell_size // 2, passenger_row * cell_size + cell_size // 2), 10)\n",
        "\n",
        "    # Desenha o destino\n",
        "    destination_coords = [(0, 0), (0, 4), (4, 0), (4, 3)]  # Locais fixos de destino\n",
        "    destination_row, destination_col = destination_coords[destination]\n",
        "    pygame.draw.circle(screen, colors[\"destination\"],\n",
        "                       (destination_col * cell_size + cell_size // 2, destination_row * cell_size + cell_size // 2), 10)\n",
        "\n",
        "    pygame.display.flip()  # Atualiza a janela com o novo estado\n",
        "\n",
        "# Treinamento do agente com Q-Learning\n",
        "for episode in range(num_episodes):\n",
        "    reset_result = env.reset()  # Reseta o ambiente para o início do episódio\n",
        "    # Para versões recentes do Gym, verifica o tipo do retorno\n",
        "    state = reset_result if isinstance(reset_result, int) else reset_result[0]\n",
        "    done = False  # Define o episódio como não terminado\n",
        "\n",
        "    while not done:\n",
        "        # Escolha da ação: Exploração (aleatória) ou Exploração (melhor ação)\n",
        "        if np.random.uniform(0, 1) < epsilon:\n",
        "            action = env.action_space.sample()  # Escolha aleatória\n",
        "        else:\n",
        "            action = np.argmax(q_table[state])  # Melhor ação com base na tabela Q\n",
        "\n",
        "        # Realiza a ação escolhida e obtém o próximo estado, recompensa e estado de término\n",
        "        step_result = env.step(action)\n",
        "        # Para versões recentes do Gym, verifica o tipo do retorno\n",
        "        next_state = step_result[0] if isinstance(step_result, tuple) else step_result\n",
        "        reward = step_result[1]  # Recompensa obtida pela ação\n",
        "        done = step_result[2]  # Verifica se o episódio terminou\n",
        "\n",
        "        # Atualiza a tabela Q usando a fórmula do Q-Learning\n",
        "        old_value = q_table[state, action]\n",
        "        next_max = np.max(q_table[next_state])  # Melhor estimativa para o próximo estado\n",
        "        q_table[state, action] = old_value + alpha * (reward + gamma * next_max - old_value)\n",
        "\n",
        "        # Atualiza o estado atual para o próximo estado\n",
        "        state = next_state\n",
        "\n",
        "# Teste do agente treinado com visualização\n",
        "reset_result = env.reset()  # Reseta o ambiente para o início do teste\n",
        "state = reset_result if isinstance(reset_result, int) else reset_result[0]\n",
        "done = False  # Define o episódio como não terminado\n",
        "\n",
        "while not done:\n",
        "    for event in pygame.event.get():  # Verifica eventos do Pygame (como fechar a janela)\n",
        "        if event.type == pygame.QUIT:\n",
        "            pygame.quit()\n",
        "            quit()\n",
        "\n",
        "    # Escolhe a melhor ação com base na tabela Q treinada\n",
        "    action = np.argmax(q_table[state])\n",
        "\n",
        "    # Executa a ação e avança para o próximo estado\n",
        "    step_result = env.step(action)\n",
        "    state = step_result[0] if isinstance(step_result, tuple) else step_result\n",
        "    done = step_result[2]  # Verifica se o episódio terminou\n",
        "\n",
        "    # Renderiza o ambiente no Pygame\n",
        "    render_env(state)\n",
        "    time.sleep(0.5)  # Pausa para visualização mais lenta\n",
        "\n",
        "pygame.quit()  # Encerra o Pygame\n"
      ],
      "metadata": {
        "id": "sdhvl0IM9t7D"
      },
      "execution_count": 5,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPGmZ3Ad1961DEHAEXfglPI",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}