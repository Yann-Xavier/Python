{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yann-Xavier/Python/blob/main/Taxi_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "from stable_baselines3 import PPO\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import json\n",
        "\n",
        "# Criar o ambiente\n",
        "env = gym.make(\"Taxi-v3\", render_mode=\"human\")\n",
        "\n",
        "# Ajuste de hiperparâmetros para melhorar o aprendizado\n",
        "model = PPO(\n",
        "    \"MlpPolicy\",\n",
        "    env,\n",
        "    verbose=1,\n",
        "    learning_rate=0.0003,\n",
        "    n_steps=2048,\n",
        "    batch_size=64,\n",
        "    gamma=0.99,\n",
        "    ent_coef=0.01,\n",
        "    vf_coef=0.5,\n",
        "    max_grad_norm=0.5,  # Limitar o gradiente para estabilizar o aprendizado\n",
        "    gae_lambda=0.95,    # Melhorar a estimativa de vantagens com GAE (Generalized Advantage Estimation)\n",
        "    clip_range=0.2,     # Ajustar o intervalo de clipping para PPO\n",
        ")\n",
        "\n",
        "# Variáveis globais\n",
        "total_points = 0\n",
        "penalty_for_waiting = -0.1  # Penalidade por ficar parado\n",
        "time_to_pick_penalty = 0.05  # Penalidade por demorar para pegar o passageiro\n",
        "log_file_path = 'agent_scores.json'  # Caminho do arquivo de log\n",
        "\n",
        "\n",
        "# Função para customizar recompensas\n",
        "def custom_reward(action, reward, steps_without_pickup, has_passenger):\n",
        "    global total_points\n",
        "\n",
        "    # Penalidade por ação de 'esperar'\n",
        "    if action == 4:\n",
        "        reward += penalty_for_waiting\n",
        "\n",
        "    # Penalidade adicional por tempo sem pegar o passageiro\n",
        "    if not has_passenger:\n",
        "        reward -= time_to_pick_penalty * steps_without_pickup\n",
        "\n",
        "    # Recompensa adicional ao pegar ou entregar o passageiro\n",
        "    if reward == 20:\n",
        "        if not has_passenger:  # Pegou o passageiro\n",
        "            total_points += 1\n",
        "            print(\"Passageiro pego! +1 ponto\")\n",
        "        else:  # Deixou o passageiro\n",
        "            total_points += 1\n",
        "            print(\"Passageiro entregue ao hotel! +1 ponto\")\n",
        "\n",
        "    return reward\n",
        "\n",
        "\n",
        "# Função para gerenciar a lógica de coleta e entrega de passageiros\n",
        "def update_passenger_status(action, reward, has_passenger, steps_without_pickup):\n",
        "    if reward == 20 and not has_passenger:  # Pegou o passageiro\n",
        "        has_passenger = True\n",
        "        steps_without_pickup = 0  # Resetar o contador de tempo\n",
        "    elif reward == 20 and has_passenger:  # Deixou o passageiro\n",
        "        has_passenger = False\n",
        "\n",
        "    return has_passenger, steps_without_pickup\n",
        "\n",
        "\n",
        "# Função para treinar o modelo\n",
        "def train_model(model, total_timesteps):\n",
        "    print(\"Iniciando o treinamento...\")\n",
        "    model.learn(total_timesteps=total_timesteps)\n",
        "\n",
        "\n",
        "# Função para registrar a pontuação\n",
        "def log_scores(score_history):\n",
        "    # Salvar os scores no formato JSON\n",
        "    if os.path.exists(log_file_path):\n",
        "        with open(log_file_path, 'r') as f:\n",
        "            scores_data = json.load(f)\n",
        "    else:\n",
        "        scores_data = []\n",
        "\n",
        "    scores_data.append(score_history)\n",
        "\n",
        "    with open(log_file_path, 'w') as f:\n",
        "        json.dump(scores_data, f, indent=4)\n",
        "\n",
        "    print(f\"Pontuação salva em: {log_file_path}\")\n",
        "\n",
        "\n",
        "# Função para salvar o modelo treinado\n",
        "def save_model(model, filename=\"taxi_agent_model\"):\n",
        "    model.save(filename)\n",
        "    print(f\"Modelo salvo como: {filename}.zip\")\n",
        "\n",
        "\n",
        "# Função para testar o modelo e coletar métricas de desempenho\n",
        "def test_model(model, max_steps=1000):\n",
        "    global total_points\n",
        "    obs, info = env.reset()\n",
        "    print(\"Executando o modelo treinado...\")\n",
        "\n",
        "    steps_without_pickup = 0\n",
        "    has_passenger = False\n",
        "    score_history = []  # Lista para armazenar a pontuação ao longo do tempo\n",
        "    episode_rewards = []  # Recompensa total por episódio\n",
        "    episode_lengths = []  # Número de passos por episódio\n",
        "\n",
        "    for _ in range(max_steps):\n",
        "        action, _ = model.predict(obs, deterministic=True)\n",
        "\n",
        "        if isinstance(action, np.ndarray):\n",
        "            action = action.item()\n",
        "\n",
        "        # Observar o resultado da ação\n",
        "        obs, reward, terminated, truncated, info = env.step(action)\n",
        "\n",
        "        # Customizar a recompensa\n",
        "        reward = custom_reward(action, reward, steps_without_pickup, has_passenger)\n",
        "\n",
        "        # Atualizar o status do passageiro\n",
        "        has_passenger, steps_without_pickup = update_passenger_status(action, reward, has_passenger, steps_without_pickup)\n",
        "\n",
        "        # Penalidade com base no tempo\n",
        "        if not has_passenger:\n",
        "            steps_without_pickup += 1\n",
        "\n",
        "        # Renderizar o ambiente\n",
        "        env.render()\n",
        "\n",
        "        # Atualizar a pontuação e salvar o histórico\n",
        "        score_history.append(total_points)\n",
        "\n",
        "        # Salvar as recompensas por episódio\n",
        "        if terminated or truncated:\n",
        "            episode_rewards.append(total_points)\n",
        "            episode_lengths.append(_)\n",
        "            print(f\"Pontos acumulados neste episódio: {total_points}\")\n",
        "            obs, info = env.reset()\n",
        "            total_points = 0\n",
        "            steps_without_pickup = 0\n",
        "            has_passenger = False\n",
        "\n",
        "    # Plotar a pontuação durante a execução\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(score_history)\n",
        "    plt.title(\"Pontuação ao longo do tempo\")\n",
        "    plt.xlabel(\"Passos\")\n",
        "    plt.ylabel(\"Pontuação\")\n",
        "\n",
        "    # Plotar recompensas e duração dos episódios\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(episode_rewards, label='Recompensa do Episódio')\n",
        "    plt.plot(episode_lengths, label='Comprimento do Episódio')\n",
        "    plt.title(\"Recompensas e Comprimento do Episódio\")\n",
        "    plt.xlabel(\"Episódios\")\n",
        "    plt.ylabel(\"Valor\")\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Log de pontuação\n",
        "    log_scores(score_history)\n",
        "\n",
        "    env.close()\n",
        "    print(\"Execução finalizada.\")\n",
        "\n",
        "\n",
        "# Executando o treinamento e teste\n",
        "train_model(model, total_timesteps=500000)  # Aumentando os timesteps para maior exploração\n",
        "test_model(model)\n",
        "\n",
        "# Salvar o modelo treinado\n",
        "save_model(model)\n"
      ],
      "metadata": {
        "id": "sdhvl0IM9t7D",
        "outputId": "b7e64590-1a72-4a60-9b90-4ea1d09c6cba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'gymnasium'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-3c99566f902e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgymnasium\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstable_baselines3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPPO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gymnasium'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMDQs5F1Nufu+pSYOWd81I3",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}